model:
  base_learning_rate: 4.5e-6
  max_epochs: 50
  target: DAEFR.models.vqgan_origin.DAEFRModel
  params:
    image_key: "gt"
    # batchsize 16
    schedule_step: [400000, 800000]
    ddconfig:
      target: DAEFR.modules.vqvae.vqvae_arch.SharedEncDualDecVQModel
      params:
        checkpoint: experiments/dualdecoder.ckpt # pretrained weights of DAEFR
        embed_dim: 256
        n_embed: 1024
        double_z: False
        z_channels: 256
        resolution: 512
        in_channels: 3
        out_ch: 3
        ch: 64
        ch_mult: [1, 2, 2, 4, 4, 8] # num_down = len(ch_mult)-1
        num_res_blocks: 2
        attn_resolutions: [16]
        dropout: 0.0
        enable_mid: True
        fix_decoder: False
        fix_codebook: False

    lossconfig:
      target: DAEFR.modules.losses.vqperceptual.DualTaskVQLoss
      params:
        disc_conditional: False
        disc_in_channels: 3
        disc_start: 10001 # 30001
        disc_weight: 0.8
        codebook_weight: 1.0
        use_actnorm: False

data:
  target: main_for_codebook.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 8
    train:
      target: dataset_multipie.MultiPIEDataset
      params:
        dataroot: /vcl4/Jiseung/datasets/multipie_crop_patch_v2
        phase: train
        res: 512

    validation:
      target: dataset_multipie.MultiPIEDataset
      params:
        dataroot: /vcl4/Jiseung/datasets/multipie_crop_patch_v2
        phase: test
        res: 512
